{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"e107781e-e20e-460e-bcbb-1790be1a4eb7","_uuid":"96519959-6f65-4cc9-949a-1ad1f254c85a","collapsed":false,"execution":{"iopub.execute_input":"2022-10-19T06:47:54.239510Z","iopub.status.busy":"2022-10-19T06:47:54.239155Z","iopub.status.idle":"2022-10-19T06:53:16.836925Z","shell.execute_reply":"2022-10-19T06:53:16.835889Z","shell.execute_reply.started":"2022-10-19T06:47:54.239476Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"ename":"OSError","evalue":"[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn [2], line 67\u001b[0m\n\u001b[1;32m     64\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdropna()\n\u001b[1;32m     66\u001b[0m \u001b[39m# Select english comments\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39men_core_web_sm\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     68\u001b[0m Language\u001b[39m.\u001b[39mfactory(\u001b[39m\"\u001b[39m\u001b[39mlanguage_detector\u001b[39m\u001b[39m\"\u001b[39m, func \u001b[39m=\u001b[39m get_lang_detector)\n\u001b[1;32m     69\u001b[0m nlp\u001b[39m.\u001b[39madd_pipe(\u001b[39m'\u001b[39m\u001b[39mlanguage_detector\u001b[39m\u001b[39m'\u001b[39m, last \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/site-packages/spacy/__init__.py:54\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[1;32m     31\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[1;32m     32\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     38\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[1;32m     39\u001b[0m     \u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m     55\u001b[0m         name,\n\u001b[1;32m     56\u001b[0m         vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[1;32m     57\u001b[0m         disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[1;32m     58\u001b[0m         enable\u001b[39m=\u001b[39;49menable,\n\u001b[1;32m     59\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m     60\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m     61\u001b[0m     )\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/site-packages/spacy/util.py:436\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m    435\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE941\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname, full\u001b[39m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[39m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> 436\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE050\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname))\n","\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."]}],"source":["import numpy as np \n","import pandas as pd \n","import torch\n","import torch.utils.data as data\n","import torch.nn as nn\n","import torch.optim as optim\n","from transformers import DistilBertModel, BertConfig, DistilBertTokenizer\n","from types import SimpleNamespace\n","from torch.utils.data import DataLoader\n","import os\n","import csv\n","from transformers import AutoModel, AutoTokenizer\n","from sklearn.model_selection import train_test_split\n","import mlflow\n","import re\n","import spacy\n","from spacy.language import Language\n","from spacy_langdetect import LanguageDetector\n","\n","from codecarbon import EmissionsTracker\n","\n","MODEL = \"distilbert-base-cased\"\n","\n","\n","tokenizer = DistilBertTokenizer.from_pretrained(MODEL, max_length=512, padding=True, truncation = True, return_tensors=\"pt\")\n","\n","args = SimpleNamespace(\n","    batch_size = 1,                         # training and valid batch size\n","    test_batch_size = 1,                       # batch size for testing\n","    epochs = 15,                                 # maximum number of epochs to train\n","    lr = 0.0015,                                 # learning rate\n","    momentum = 0.9,                              # SGD momentum, for SGD only\n","    optimizer = 'adam',                          # optimization method: sgd | adam\n","    log_interval = 5,                            # how many batches to wait before logging training status\n","    patience = 5,                                # how many epochs of no loss improvement should we wait before stop training\n","    checkpoint = '.',\n","    seed = 42,                            # checkpoints directory\n","    train = True,                                # train before testing\n","    cuda = True,                                 # use gpu\n","    num_workers = 2,                             # how many subprocesses to use for data loading\n","    adapter_hidden_size = 32,\n","    acc_steps = 40\n",")\n","\n","\n","def get_lang_detector(nlp, name):\n","    return LanguageDetector()\n","\n","\n","# Given the list with the classes for each comment, returns the output with the desired format\n","def prepare_target(sentiments):\n","    target = []\n","    for sent in sentiments:\n","        if sent == 0:\n","            target.append([1.0,0.0])#,0.0]) #target.append([1.0,0.0])\n","        elif sent == 1:\n","            target.append([0.0,1.0,0.0])\n","        else:\n","            target.append([0.0,1.0])#,1.0]) # target.append([0.0,1.0])\n","    return torch.tensor(target)\n","\n","file = \"../data/processed/comments_clean.csv\"\n","df = pd.read_csv(file)\n","df = df.dropna()\n","\n","# Select english comments\n","nlp = spacy.load(\"en_core_web_sm\")\n","Language.factory(\"language_detector\", func = get_lang_detector)\n","nlp.add_pipe('language_detector', last = True)\n","\n","languages = []\n","for i, row in df.iterrows():\n","    languages.append(nlp(row[\"Comment\"])._.language['language'])\n","df[\"Language\"] = languages\n","df = df[df[\"Language\"] == 'en']\n","\n","df0 = df[df['Sentiment'] == 0]\n","#df1 = df[df['Sentiment'] == 1]\n","df2 = df[df['Sentiment'] == 2]\n","l = min(len(df0), len(df2))#, len(df2))\n","\n","df = pd.concat([df0.sample(n=l),df2.sample(n=l)])#, df2.sample(n=l)])#,df2[:l]])\n","comments = df['Comment'].tolist() # The tokenizer recieves a list as input \n","\n","def convert_emojis(text):\n","    for emot in UNICODE_EMO:\n","        text = re.sub(r'('+emot+')', \"_\".join(UNICODE_EMO[emot].replace(\",\",\"\").replace(\":\",\"\").split()), text)\n","    return text\n","\n","    \n","target = prepare_target(df['Sentiment']) \n","X_train, X_test, y_train, y_test = train_test_split(comments, target, test_size=0.2, random_state=args.seed)\n","X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=args.seed)\n","\n","\n","\n","class Loader(torch.utils.data.Dataset):\n","  def __init__(self, comments, sentiments):\n","    self.data= tokenizer(comments, padding=True, truncation = True, max_length=512,return_tensors=\"pt\")['input_ids']\n","    self.target = sentiments\n","    \n","  def __getitem__(self, index):\n","    data = self.data[index]\n","    target = self.target[index]\n","    return data, target\n","  \n","  def __len__(self):\n","        return len(self.target)\n","\n","\n","class DistilBERTforSentiment(nn.Module):\n","    def __init__(self, adapter_hidden_size=args.adapter_hidden_size):\n","        super().__init__()\n","\n","        self.distilbert = DistilBertModel.from_pretrained(MODEL)\n","        \n","        hidden_size = self.distilbert.config.hidden_size\n","\n","        self.adaptor = nn.Sequential(\n","            nn.Linear(hidden_size, adapter_hidden_size),\n","            nn.ReLU(True),           \n","            nn.Dropout(0.2),            \n","            nn.Linear(adapter_hidden_size, hidden_size),\n","        )  \n","        \n","        self.classifier = nn.Sequential(\n","            nn.Linear(hidden_size, adapter_hidden_size),\n","            nn.ReLU(True),           \n","            nn.Dropout(0.2),            \n","            nn.Linear(adapter_hidden_size, 2),\n","        )\n","        \n","        \n","    def forward(self, inputs):\n","        outputs = self.distilbert(input_ids = inputs, return_dict=False)\n","        # B x seq_length x H\n","        x = self.adaptor(outputs[0])\n","        \n","        x,_ = x.max(dim=1)\n","        # B x H\n","        \n","        results = self.classifier(x)\n","        return results\n","\n","\n","args.cuda = args.cuda and torch.cuda.is_available()\n","if args.cuda:\n","    print('Using CUDA with {0} GPUs'.format(torch.cuda.device_count()))\n","\n","# build model\n","model = DistilBERTforSentiment(adapter_hidden_size=args.adapter_hidden_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-19T06:53:16.839499Z","iopub.status.busy":"2022-10-19T06:53:16.839049Z","iopub.status.idle":"2022-10-19T06:53:30.319319Z","shell.execute_reply":"2022-10-19T06:53:30.318223Z","shell.execute_reply.started":"2022-10-19T06:53:16.839459Z"},"trusted":true},"outputs":[],"source":["for param in model.distilbert.parameters():\n","    param.requires_grad = False\n","    \n","if args.cuda:\n","    model.cuda()\n","\n","# Define criterion\n","criterion = nn.CrossEntropyLoss()\n","\n","\n","def train_one_epoch(trainloader, model, criterion, optimizer, epoch_index, cuda,max_norm=1):\n","    model.train()\n","    running_loss = 0\n","    accumulation_steps = args.acc_steps # effective  batch  \n","    for i, (input_ids,target) in enumerate(trainloader, 0):\n","        if cuda:\n","            input_ids, target = input_ids.cuda(), target.cuda()\n","        output = model(input_ids)\n","        \n","        loss = criterion(output, target)\n","        #print(\"output \", output,\" target: \", target, \" \", i)\n","        loss.backward()\n","        #nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n","        if (i+1) % accumulation_steps == 0:\n","            optimizer.step()                 # Now we can do an optimizer step\n","            optimizer.zero_grad()\n","        running_loss += loss.item()\n","        if i % 1000 == 999:\n","            last_loss = running_loss / 1000 # loss per batch\n","            print('  batch {} loss: {}'.format(i + 1, last_loss))\n","            tb_x = epoch_index * len(trainloader) + i + 1\n","            print('Loss/train', last_loss, tb_x)\n","            running_loss = 0.\n","    return running_loss / i\n","\n","\n","def test_one_epoch(test_loader,model,criterion, cuda, avg_loss):\n","    running_vloss = 0.0\n","    best_vloss = 99999\n","    acc = 0\n","    _p = 0.0000000001 # prediction: not pos, target: pos\n","    _n = 0.0000000001 # prediction: not neg, target: neg\n","    _t = 0.0000000001 # prediction: not neutral, target: neutral\n","    pp = 0.0000000001 # prediction: pos, target: pos\n","    nn = 0.0000000001 # prediction: neg, target: neg\n","    tt = 0.0000000001 # prediction: neutral, target: neutral\n","    p_ = 0.0000000001 # prediction: pos, target: not pos\n","    n_ = 0.0000000001 # prediction: neg, target: not neg\n","    t_ = 0.0000000001 # prediction: neutral, target: not neutral\n","    for i, (input_ids,target) in enumerate(test_loader, 0):\n","        if cuda:\n","            input_ids, target = input_ids.cuda(), target.cuda()\n","        output = model(input_ids)\n","        loss = criterion(output, target)\n","        running_vloss += loss\n","        obj = torch.Tensor.int(target.argmax())\n","        out = torch.Tensor.int(output.argmax())\n","        if out == obj:\n","            acc += 1\n","            if obj == 0:\n","                nn += 1\n","            else:\n","                pp += 1\n","            #else:\n","            #    pp += 1\n","        else:\n","            if obj == 0:\n","                _n += 1\n","            else:\n","                _p += 1\n","            #else:\n","            #   _p += 1\n","            if out == 0:\n","                n_ += 1\n","            else:\n","                p_ += 1\n","            #else:\n","            #    p_ += 1\n","                \n","    prec_pos = pp/(pp + p_)\n","    prec_neg = nn/(nn + n_)\n","    #prec_neu = tt/(tt + t_)\n","    rec_pos = pp/(pp + _p)\n","    rec_neg = nn/(nn + _n)\n","    #rec_neu = tt/(tt + _t)\n","    avg_vloss = running_vloss / (i + 1)\n","    acc = acc/(i+1)\n","    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n","    print('Accuracy= {}'.format(acc))\n","    return acc, avg_vloss, rec_neg, 0, rec_pos, prec_neg, 0, prec_pos\n","\n","#targets = np.array(df['Sentiment'].to_list(), dtype = np.int32)\n","#class_sample_count = np.array([len(np.where(targets == t)[0]) for t in [0,1,2]])\n","#weight = 1. / class_sample_count\n","#samples_weight = np.array([weight[t] for t in targets])\n","\n","#samples_weight = torch.from_numpy(samples_weight)\n","#samples_weigth = samples_weight.double()\n","#sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weight, len(samples_weight))\n","\n","#target = torch.from_numpy(target).long()\n","#train_dataset = torch.utils.data.TensorDataset(data, target)\n","\n","#train_loader = DataLoader(\n","#    train_dataset, batch_size=bs, num_workers=1, sampler=sampler)\n","\n","print(\"Preparing training set...\")\n","training_set = Loader(X_train, y_train) \n","train_loader = torch.utils.data.DataLoader(training_set, batch_size=args.batch_size,\n","                                        num_workers=0, shuffle = True)\n","print(\"Preparing validation set...\")\n","\n","valid_set = Loader(X_valid, y_valid) \n","valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=args.test_batch_size,\n","                                           num_workers=0, shuffle = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-19T06:53:30.321900Z","iopub.status.busy":"2022-10-19T06:53:30.321135Z","iopub.status.idle":"2022-10-19T06:53:30.332642Z","shell.execute_reply":"2022-10-19T06:53:30.331653Z","shell.execute_reply.started":"2022-10-19T06:53:30.321856Z"},"trusted":true},"outputs":[],"source":["''''optimizer = optim.Adam(model.parameters(), lr=args.lr)\n","epoch = 0\n","best_valid_loss = 9999\n","\n","\n","\n","\n","while (epoch < args.epochs + 1):\n","    train_loss = train_one_epoch(train_loader, model, criterion, optimizer, epoch, args.cuda)\n","    acc, valid_loss = test_one_epoch(test_loader, model, criterion, args.cuda, train_loss)\n","    if not os.path.isdir(args.checkpoint):\n","        os.mkdir(args.checkpoint)\n","    torch.save(model.state_dict(), './{}/model{:03d}.pt'.format(args.checkpoint, epoch))\n","    if valid_loss <= best_valid_loss:\n","        print('Saving state')\n","        best_valid_loss = valid_loss\n","        best_epoch = epoch\n","        state = {\n","            'valid_loss': valid_loss,\n","            'epoch': epoch,\n","        }\n","        if not os.path.isdir(args.checkpoint):\n","            os.mkdir(args.checkpoint)\n","        torch.save(state, './{}/ckpt.pt'.format(args.checkpoint))\n","    \n","    print(\"End epoch \", epoch)\n","    epoch += 1\n","#emissions: float = tracker.stop()'''"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b17e01f5-a4e9-42bd-bfe9-bf3e2a5731ba","_uuid":"382eeccb-4d5f-41ff-9dff-50954ce43502","collapsed":false,"execution":{"iopub.execute_input":"2022-10-19T06:53:30.335520Z","iopub.status.busy":"2022-10-19T06:53:30.333886Z","iopub.status.idle":"2022-10-19T07:11:28.195508Z","shell.execute_reply":"2022-10-19T07:11:28.194356Z","shell.execute_reply.started":"2022-10-19T06:53:30.335484Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["    \n","optimizer = optim.Adam(model.parameters(), lr=args.lr)\n","epoch = 0\n","best_valid_loss = 9999\n","experiment_name = \"2 classes-2\"#\"40.32.09.003.10\"\n","mlflow.set_tracking_uri(\"https://dagshub.com/danielgonzalbez/taed.mlflow\")\n","os.environ['MLFLOW_TRACKING_USERNAME'] = 'danielgonzalbez'\n","os.environ['MLFLOW_TRACKING_PASSWORD'] = 'iqh601lm'\n","print(\"Creating experiment...\")\n","experiment_id = mlflow.create_experiment(experiment_name)\n","print(\"Starting the experiment...\")\n","\n","\n","\n","\n","tracker = EmissionsTracker()\n","tracker.start()\n","with mlflow.start_run(experiment_id = experiment_id):\n","    mlflow.log_param(\"batch_size\", args.acc_steps)\n","    mlflow.log_param(\"adapter_hidden_size\", args.adapter_hidden_size)\n","    mlflow.log_param(\"momentum\", args.momentum)\n","    mlflow.log_param(\"lr\", args.lr)\n","    mlflow.log_param(\"epochs\", args.epochs)\n","    while (epoch < args.epochs + 1):\n","        train_loss = train_one_epoch(train_loader, model, criterion, optimizer, epoch, args.cuda)\n","        acc, valid_loss, rec_neg, rec_neu, rec_pos, prec_neg, prec_neu, prec_pos = test_one_epoch(valid_loader, model, criterion, args.cuda, train_loss)\n","        if not os.path.isdir(args.checkpoint):\n","            os.mkdir(args.checkpoint)\n","        torch.save(model.state_dict(), './{}/model{:03d}.pt'.format(args.checkpoint, epoch))\n","        if valid_loss <= best_valid_loss:\n","            print('Saving state')\n","            best_valid_loss = valid_loss\n","            best_epoch = epoch\n","            mlflow.log_artifact('./{}/model{:03d}.pt'.format(args.checkpoint, epoch))\n","            state = {\n","                'valid_loss': valid_loss,\n","                'epoch': epoch,\n","            }\n","            if not os.path.isdir(args.checkpoint):\n","                os.mkdir(args.checkpoint)\n","            torch.save(state, './{}/ckpt.pt'.format(args.checkpoint))\n","            \n","            print ('logging accuracy...')\n","            mlflow.log_metric(\"accuracy\", acc)\n","            print('logging loss...')\n","            mlflow.log_metric(\"loss\", valid_loss)\n","            mlflow.log_metric(\"Negative recall\", rec_neg)\n","            #mlflow.log_metric(\"Neutral recall\", rec_neu)\n","            mlflow.log_metric(\"Positive recall\", rec_pos)\n","            mlflow.log_metric(\"Negative precision\", prec_neg)\n","            #mlflow.log_metric(\"Neutral precision\", prec_neu)\n","            mlflow.log_metric(\"Positive precision\", prec_pos)\n","            mlflow.log_metric(\"Best epoch\", epoch)\n","        print(\"End epoch \", epoch)\n","        \n","        epoch += 1\n","    emissions = tracker.stop()\n","    mlflow.log_metric(\"Emissions\", emissions)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-19T07:11:28.199107Z","iopub.status.busy":"2022-10-19T07:11:28.198783Z","iopub.status.idle":"2022-10-19T07:11:28.211753Z","shell.execute_reply":"2022-10-19T07:11:28.210824Z","shell.execute_reply.started":"2022-10-19T07:11:28.199079Z"},"trusted":true},"outputs":[],"source":["class DistilBERTforSentiment(nn.Module):\n","    def __init__(self, adapter_hidden_size=32):\n","        super().__init__()\n","\n","        self.distilbert = DistilBertModel.from_pretrained(MODEL)\n","        \n","        hidden_size = self.distilbert.config.hidden_size\n","\n","        self.adaptor = nn.Sequential(\n","            nn.Linear(hidden_size, adapter_hidden_size),\n","            nn.ReLU(True),           \n","            nn.Dropout(0.2),            \n","            nn.Linear(adapter_hidden_size, hidden_size),\n","        )  \n","        \n","        self.classifier = nn.Sequential(\n","            nn.Linear(hidden_size, adapter_hidden_size),\n","            nn.ReLU(True),           \n","            nn.Dropout(0.2),            \n","            nn.Linear(adapter_hidden_size, 2),\n","        )\n","        \n","        \n","    def forward(self, inputs):\n","        outputs = self.distilbert(input_ids = inputs, return_dict=False)\n","        # B x seq_length x H\n","        x = self.adaptor(outputs[0])\n","        \n","        x,_ = x.max(dim=1)\n","        # B x H\n","        \n","        results = self.classifier(x)\n","        return results\n","\n","def make_model():\n","    model = DistilBERTforSentiment(adapter_hidden_size=32)\n","    return model\n","\n","\n","\n","class Loader(torch.utils.data.Dataset):\n","    def __init__(self, comments, sentiments):\n","        self.data= tokenizer(comments, padding=True, truncation = True, max_length=512,return_tensors=\"pt\")['input_ids']\n","        self.target = sentiments\n","        \n","    def __getitem__(self, index):\n","        data = self.data[index]\n","        target = self.target[index]\n","        return data, target\n","  \n","    def __len__(self):\n","        return len(self.data)\n","\n","\n","def prepare_pred(comment, sentiment):\n","    pre_loader = Loader(comment, [1]) \n","    loader = torch.utils.data.DataLoader(pre_loader, batch_size=1,\n","                                          shuffle=True, num_workers=0)\n","    return loader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-19T07:11:28.213684Z","iopub.status.busy":"2022-10-19T07:11:28.213310Z","iopub.status.idle":"2022-10-19T07:11:31.528034Z","shell.execute_reply":"2022-10-19T07:11:31.526449Z","shell.execute_reply.started":"2022-10-19T07:11:28.213646Z"},"trusted":true},"outputs":[],"source":["state = torch.load('./{}/ckpt.pt'.format(args.checkpoint))\n","epoch = state['epoch']\n","print(\"Testing model (epoch {})\".format(epoch))\n","#model.load_state_dict(torch.load('./{}/model{:03d}.pt'.format(args.checkpoint, epoch)))\n","\n","model = make_model()\n","model.load_state_dict(torch.load('./{}/model{:03d}.pt'.format(args.checkpoint, epoch)))\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-19T07:11:31.536588Z","iopub.status.busy":"2022-10-19T07:11:31.533400Z","iopub.status.idle":"2022-10-19T07:11:33.088839Z","shell.execute_reply":"2022-10-19T07:11:33.087775Z","shell.execute_reply.started":"2022-10-19T07:11:31.536557Z"},"trusted":true},"outputs":[],"source":["test_set = Loader(X_test, y_test) \n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=args.test_batch_size,\n","                                           num_workers=0, shuffle = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-19T07:11:33.090982Z","iopub.status.busy":"2022-10-19T07:11:33.090272Z","iopub.status.idle":"2022-10-19T07:23:30.032661Z","shell.execute_reply":"2022-10-19T07:23:30.031431Z","shell.execute_reply.started":"2022-10-19T07:11:33.090945Z"},"trusted":true},"outputs":[],"source":["#data = prepare_pred(df['Comment'][18234])\n","acc = 0\n","num1 = 0\n","num0 = 0\n","\n","# i_j = Predicted i, Target j\n","_p = 0.0000000001 # prediction: not pos, target: pos\n","_n = 0.0000000001 # prediction: not neg, target: neg\n","_t = 0.0000000001 # prediction: not neutral, target: neutral\n","pp = 0.0000000001 # prediction: pos, target: pos\n","nn = 0.0000000001 # prediction: neg, target: neg\n","tt = 0.0000000001 # prediction: neutral, target: neutral\n","p_ = 0.0000000001 # prediction: pos, target: not pos\n","n_ = 0.0000000001 # prediction: neg, target: not neg\n","t_ = 0.0000000001 # prediction: neutral, target: not neutral\n","\n","for i, (input_ids, target) in enumerate(test_loader):\n","    output = model(input_ids)\n","    obj = torch.Tensor.int(target.argmax())\n","    out = torch.Tensor.int(output.argmax())\n","    if out == obj:\n","        acc += 1\n","        if obj == 0:\n","            nn += 1\n","        else:\n","            pp += 1\n","        #else:\n","        #    pp += 1\n","    else:\n","        if obj == 0:\n","            _n += 1\n","        else:\n","            _p += 1\n","        #else:\n","        #   _p += 1\n","        if out == 0:\n","            n_ += 1\n","        else:\n","            p_ += 1\n","        #else:\n","        #    p_ += 1\n","    if(i%100 == 0):\n","        print(i, \" \",acc/(i+1))\n","        \n","prec_pos = pp/(pp + p_)\n","prec_neg = nn/(nn + n_)\n","#prec_neu = tt/(tt + t_)\n","rec_pos = pp/(pp + _p)\n","rec_neg = nn/(nn + _n)\n","#rec_neu = tt/(tt + _t)\n","print(\"FINAL ACCURACY: \", acc/i)\n","print(\"Positive Recall: \", rec_pos)\n","print(\"Negative Recall: \", rec_neg)\n","#print(\"Neutral Recall: \", rec_neu)\n","print(\"Negative Precision: \", prec_neg)\n","#print(\"Neutral Precision: \", prec_neu)\n","print(\"Positive Precision: \", prec_pos)\n","\n","\n","print(\"F1-Score Positive: \", (2*prec_pos*rec_pos/(prec_pos+rec_pos)))\n","print(\"F1-Score Negative: \", (2*prec_neg*rec_neg/(prec_neg+rec_neg)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-19T07:27:41.835709Z","iopub.status.busy":"2022-10-19T07:27:41.835355Z","iopub.status.idle":"2022-10-19T07:27:41.842411Z","shell.execute_reply":"2022-10-19T07:27:41.841136Z","shell.execute_reply.started":"2022-10-19T07:27:41.835679Z"},"trusted":true},"outputs":[],"source":["print(pp, \" \", p_, \" \",_p, \" \", nn, \" \", n_, \" \",_n, \" \", tt, \" \", t_, \" \",_t)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-18T16:00:51.636686Z","iopub.status.busy":"2022-10-18T16:00:51.636252Z","iopub.status.idle":"2022-10-18T16:00:51.682544Z","shell.execute_reply":"2022-10-18T16:00:51.681451Z","shell.execute_reply.started":"2022-10-18T16:00:51.636649Z"},"trusted":true},"outputs":[],"source":["load = (prepare_pred(\"Bad video. Waste of time\", [1]))\n","for i, (input_ids,_) in enumerate(load):\n","    out2= model(input_ids)\n","print(out2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["load = (prepare_pred(\"Good video. Well done\", [1]))\n","for i, (input_ids,_) in enumerate(load):\n","    out2= model(input_ids)\n","print(out2)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["'en'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["from langdetect import detect\n","detect(\"How are you\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 ('taed')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"025c0aba4221b3da9a885e5aca70245362a44602d165372a325b50456c8902a4"}}},"nbformat":4,"nbformat_minor":4}
