{"cells":[{"cell_type":"code","execution_count":13,"metadata":{"id":"qCM0rFgQhltK"},"outputs":[{"name":"stderr","output_type":"stream","text":["The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"]},{"name":"stdout","output_type":"stream","text":["Moving 0 files to the new cache system\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3889361b8e0b4184a82d54c15a33e43e","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import numpy as np \n","import pandas as pd \n","import torch\n","import torch.utils.data as data\n","import torch.nn as nn\n","import torch.optim as optim\n","from transformers import DistilBertModel, BertConfig, DistilBertTokenizer\n","from types import SimpleNamespace\n","from torch.utils.data import DataLoader\n","import os\n","import csv\n","from transformers import AutoModel, AutoTokenizer\n","from sklearn.model_selection import train_test_split\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"MBNIrgJRWQgY"},"outputs":[],"source":["MODEL = \"distilbert-base-uncased\""]},{"cell_type":"code","execution_count":15,"metadata":{"id":"DyeWboKmWOnp"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0f17ea6ca43e44b18a0d5c383b0435b4","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ff31d3e763c9404fb0a9be73b85e7840","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d4cbc1089b7c43f585e3bfac559f5b1a","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizer = DistilBertTokenizer.from_pretrained(MODEL, max_length=512, padding=True, truncation = True, return_tensors=\"pt\")"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"Efwgfrlr1ywy"},"outputs":[],"source":["args = SimpleNamespace(\n","    # general options\n","    #train_path = '../input/covid2/train',        # train data folder\n","    #valid_path = '../input/covid2/valid',        # valid data folder\n","    #test_path = '../input/covid2/test',          # test data folder\n","    batch_size = 128,                         # training and valid batch size\n","    test_batch_size = 128,                       # batch size for testing\n","    epochs = 10,                                 # maximum number of epochs to train\n","    lr = 0.05,                                 # learning rate\n","    momentum = 0.9,                              # SGD momentum, for SGD only\n","    optimizer = 'adam',                          # optimization method: sgd | adam\n","    log_interval = 5,                            # how many batches to wait before logging training status\n","    patience = 5,                                # how many epochs of no loss improvement should we wait before stop training\n","    checkpoint = '../models',                    # checkpoints directory\n","    seed = 42,\n","    train = True,                                # train before testing\n","    cuda = True,                                 # use gpu\n","    num_workers = 2,                             # how many subprocesses to use for data loading\n","    adapter_hidden_size = 64\n",")"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"gJWTa_pqEWc-"},"outputs":[],"source":["# Given the list with the classes for each comment, returns the output with the desired format\n","def prepare_target(sentiments):\n","  target = []\n","  for sent in sentiments:\n","    if sent == 0:\n","      target.append([1.0,0.0,0.0])\n","    elif sent == 1:\n","      target.append([0.0,1.0,0.0])\n","    else:\n","      target.append([0.0,0.0,1.0])\n","  return torch.tensor(target)\n"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2022-09-23T17:16:59.326493Z","iopub.status.busy":"2022-09-23T17:16:59.326138Z","iopub.status.idle":"2022-09-23T17:16:59.489384Z","shell.execute_reply":"2022-09-23T17:16:59.487421Z","shell.execute_reply.started":"2022-09-23T17:16:59.326464Z"},"id":"kmDS90swYtAE","trusted":true},"outputs":[],"source":["file = \"../data/external/comments.csv\"\n","df = pd.read_csv(file)\n","df = df.dropna()\n","comments = df['Comment'].tolist() # The tokenizer recieves a list as input \n","target = prepare_target(df['Sentiment']) \n","X_train, X_test, y_train, y_test = train_test_split(comments, target, test_size=0.33, random_state=args.seed)"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"Dhlu1WF3bJqW"},"outputs":[],"source":["class Loader(torch.utils.data.Dataset):\n","  def __init__(self, comments, sentiments):\n","    self.data= tokenizer(comments, padding=True, truncation = True, max_length=512,return_tensors=\"pt\")['input_ids']\n","    self.target = sentiments\n","    \n","  def __getitem__(self, index):\n","    data = self.data[index]\n","    target = self.target[index]\n","    return data, target\n","  \n","  def __len__(self):\n","        return len(self.target)\n"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"L1Kxe-9X81O4"},"outputs":[],"source":["class DistilBERTforSentiment(nn.Module):\n","    def __init__(self, adapter_hidden_size=64):\n","        super().__init__()\n","\n","        self.distilbert = DistilBertModel.from_pretrained(MODEL)\n","        \n","        hidden_size = self.distilbert.config.hidden_size\n","\n","        self.adaptor = nn.Sequential(\n","            nn.Linear(hidden_size, adapter_hidden_size),\n","            nn.ReLU(True),           \n","            nn.Dropout(0.1),            \n","            nn.Linear(adapter_hidden_size, hidden_size),\n","        )  \n","        \n","        self.classifier = nn.Sequential(\n","            nn.Linear(hidden_size, adapter_hidden_size),\n","            nn.ReLU(True),           \n","            nn.Dropout(0.1),            \n","            nn.Linear(adapter_hidden_size, 3),\n","        )\n","        \n","        \n","    def forward(self, inputs):\n","        outputs = self.distilbert(input_ids = inputs, return_dict=False)\n","        # B x seq_length x H\n","        x = self.adaptor(outputs[0])\n","        \n","        x,_ = x.max(dim=1)\n","        # B x H\n","        \n","        results = self.classifier(x)\n","        return results"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"Z7FSqdQP8uUE","outputId":"89ef64da-dc4d-4f70-99f0-f381d766041f"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["args.cuda = args.cuda and torch.cuda.is_available()\n","if args.cuda:\n","    print('Using CUDA with {0} GPUs'.format(torch.cuda.device_count()))\n","\n","# build model\n","model = DistilBERTforSentiment(adapter_hidden_size=args.adapter_hidden_size)\n","\n","for param in model.distilbert.parameters():\n","    param.requires_grad = False\n","    \n","if args.cuda:\n","    model.cuda()\n","\n","# Define criterion\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"-q2rd9cY78UT"},"outputs":[],"source":["def train_one_epoch(trainloader, model, criterion, optimizer, epoch_index, cuda,max_norm=1):\n","    model.train()\n","    running_loss = 0\n","    accumulation_steps = 40 # effective 40 batch  \n","    for i, (input_ids,target) in enumerate(trainloader, 0):\n","        if cuda:\n","            input_ids, target = input_ids.cuda(), target.cuda()\n","        #optimizer.zero_grad()\n","        output = model(input_ids)\n","        loss = criterion(output, target)\n","        #print(torch.sigmoid(output), target)\n","        loss.backward()\n","        nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n","        if (i+1) % accumulation_steps == 0:\n","            optimizer.step()                 # Now we can do an optimizer step\n","            optimizer.zero_grad()\n","        running_loss += loss.item()\n","        if i % 1000 == 999:\n","            last_loss = running_loss / 1000 # loss per batch\n","            print('  batch {} loss: {}'.format(i + 1, last_loss))\n","            tb_x = epoch_index * len(trainloader) + i + 1\n","            print('Loss/train', last_loss, tb_x)\n","            running_loss = 0.\n","    return running_loss / i"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"3VA1U9FoBDl7"},"outputs":[],"source":["def test_one_epoch(test_loader,model,criterion, cuda, avg_loss):\n","    running_vloss = 0.0\n","    best_vloss = 99999\n","    for i, (input_ids,target) in enumerate(test_loader, 0):\n","        if cuda:\n","            input_ids, target = input_ids.cuda(), target.cuda()\n","        output = model(input_ids)\n","        loss = criterion(output, target)\n","        running_vloss += loss\n","\n","    avg_vloss = running_vloss / (i + 1)\n","    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n","    return avg_vloss"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"VszQ1drb_TqY","outputId":"9516892e-3eb3-4127-dae4-8d012cb0cae8"},"outputs":[],"source":["# num_workers set to 8 as recommended when training in local\n","training_set = Loader(X_train, y_train) #X['attention_mask']\n","train_loader = torch.utils.data.DataLoader(training_set, batch_size=1,\n","                                          shuffle=True, num_workers=8)\n","\n","test_set = Loader(X_test, y_test) #X['attention_mask']\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=1,\n","                                          shuffle=True, num_workers=8)"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"MW-ps82g8Tj0","outputId":"bf180970-8caa-4fa0-8a26-d2e1cb7c6742"},"outputs":[{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n","    exitcode = _main(fd, parent_sentinel)\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n","    self = reduction.pickle.load(from_parent)\n","AttributeError: Can't get attribute 'Loader' on <module '__main__' (built-in)>\n","Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n","    exitcode = _main(fd, parent_sentinel)\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n","    self = reduction.pickle.load(from_parent)\n","AttributeError: Can't get attribute 'Loader' on <module '__main__' (built-in)>\n","Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n","    exitcode = _main(fd, parent_sentinel)\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n","    self = reduction.pickle.load(from_parent)\n","AttributeError: Can't get attribute 'Loader' on <module '__main__' (built-in)>\n","Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n","    exitcode = _main(fd, parent_sentinel)\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n","    self = reduction.pickle.load(from_parent)\n","AttributeError: Can't get attribute 'Loader' on <module '__main__' (built-in)>\n","Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n","    exitcode = _main(fd, parent_sentinel)\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n","Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n","    self = reduction.pickle.load(from_parent)\n","AttributeError: Can't get attribute 'Loader' on <module '__main__' (built-in)>\n","    exitcode = _main(fd, parent_sentinel)\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n","    self = reduction.pickle.load(from_parent)\n","AttributeError: Can't get attribute 'Loader' on <module '__main__' (built-in)>\n","Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n","    exitcode = _main(fd, parent_sentinel)\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n","    self = reduction.pickle.load(from_parent)\n","AttributeError: Can't get attribute 'Loader' on <module '__main__' (built-in)>\n","Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n","    exitcode = _main(fd, parent_sentinel)\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n","    self = reduction.pickle.load(from_parent)\n","AttributeError: Can't get attribute 'Loader' on <module '__main__' (built-in)>\n"]},{"ename":"RuntimeError","evalue":"DataLoader worker (pid(s) 35045) exited unexpectedly","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1164\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    114\u001b[0m     \u001b[39mraise\u001b[39;00m Empty\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 262\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/connection.py:429\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 429\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    430\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     64\u001b[0m     \u001b[39m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     _error_if_any_worker_fails()\n\u001b[1;32m     67\u001b[0m     \u001b[39mif\u001b[39;00m previous_handler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 35045) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn [37], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m best_valid_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m9999\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (epoch \u001b[38;5;241m<\u001b[39m args\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m         train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m         valid_loss \u001b[38;5;241m=\u001b[39m test_one_epoch(test_loader, model, criterion, args\u001b[38;5;241m.\u001b[39mcuda, train_loss)\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(args\u001b[38;5;241m.\u001b[39mcheckpoint):\n","Cell \u001b[0;32mIn [34], line 5\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(trainloader, model, criterion, optimizer, epoch_index, cuda, max_norm)\u001b[0m\n\u001b[1;32m      3\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m accumulation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m40\u001b[39m \u001b[38;5;66;03m# effective 40 batch  \u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (input_ids,target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cuda:\n\u001b[1;32m      7\u001b[0m         input_ids, target \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mcuda(), target\u001b[38;5;241m.\u001b[39mcuda()\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1356\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1358\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1359\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1361\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1362\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1325\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1324\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1325\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1326\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1327\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1176\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(failed_workers) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1175\u001b[0m     pids_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(w\u001b[39m.\u001b[39mpid) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1176\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mDataLoader worker (pid(s) \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) exited unexpectedly\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(pids_str)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, queue\u001b[39m.\u001b[39mEmpty):\n\u001b[1;32m   1178\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n","\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 35045) exited unexpectedly"]}],"source":["optimizer = optim.Adam(model.parameters(), lr=args.lr)\n","epoch = 0\n","best_valid_loss = 9999\n","while (epoch < args.epochs + 1):\n","        train_loss = train_one_epoch(train_loader, model, criterion, optimizer, epoch, args.cuda)\n","        valid_loss = test_one_epoch(test_loader, model, criterion, args.cuda, train_loss)\n","        if not os.path.isdir(args.checkpoint):\n","            os.mkdir(args.checkpoint)\n","        torch.save(model.state_dict(), '../models/{}/model{:03d}.pt'.format(args.checkpoint, epoch))\n","        if valid_loss <= best_valid_loss:\n","            print('Saving state')\n","            best_valid_loss = valid_loss\n","            best_epoch = epoch\n","            state = {\n","                'valid_loss': valid_loss,\n","                'epoch': epoch,\n","            }\n","            if not os.path.isdir(args.checkpoint):\n","                os.mkdir(args.checkpoint)\n","            torch.save(state, './{}/ckpt.pt'.format(args.checkpoint))\n","        print(\"End epoch \", epoch)\n","        epoch += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yTLw_iE-J_l6"},"outputs":[],"source":["'''class BertforSentiment(nn.Module):\n","  def __init__(self, adapter_hidden_size=64):\n","        super().__init__()\n","        self.distilbert = Distilbert.from_pretrained(MODEL)\n","        self.hidden_size = self.distilhubert.config.hidden_size\n","        self.adaptor = nn.Sequential(\n","            nn.Linear(3*self.hidden_size, adapter_hidden_size),\n","            nn.ReLU(True),           \n","            nn.Dropout(0.1),            \n","            nn.Linear(adapter_hidden_size, self.hidden_size*3),\n","        )  \n","        \n","        self.classifier = nn.Sequential(\n","            nn.Linear(3*self.hidden_size, adapter_hidden_size),\n","            nn.ReLU(True),           \n","            nn.Dropout(0.1),            \n","            nn.Linear(adapter_hidden_size, 1),\n","        )\n","        num_layers = self.distilhubert.config.num_hidden_layers + 1 # transformer layers + input embeddings\n","        self.layer_weights = nn.Parameter(torch.tensor([1/3, 1/3, 1/3], dtype = torch.float32), requires_grad = True)'''\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 ('taed')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"025c0aba4221b3da9a885e5aca70245362a44602d165372a325b50456c8902a4"}}},"nbformat":4,"nbformat_minor":4}
