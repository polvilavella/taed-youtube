{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"qCM0rFgQhltK"},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","import torch\n","import torch.utils.data as data\n","import torch.nn as nn\n","import torch.optim as optim\n","from transformers import DistilBertModel, BertConfig, DistilBertTokenizer\n","from types import SimpleNamespace\n","from torch.utils.data import DataLoader\n","import os\n","import csv\n","from transformers import AutoModel, AutoTokenizer\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"MBNIrgJRWQgY"},"outputs":[],"source":["MODEL = \"distilbert-base-uncased\""]},{"cell_type":"code","execution_count":3,"metadata":{"id":"DyeWboKmWOnp"},"outputs":[],"source":["tokenizer = DistilBertTokenizer.from_pretrained(MODEL, max_length=512, padding=True, truncation = True, return_tensors=\"pt\")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Efwgfrlr1ywy"},"outputs":[],"source":["args = SimpleNamespace(\n","    # general options\n","    #train_path = '../input/covid2/train',        # train data folder\n","    #valid_path = '../input/covid2/valid',        # valid data folder\n","    #test_path = '../input/covid2/test',          # test data folder\n","    batch_size = 32,                         # training and valid batch size\n","    test_batch_size = 32,                       # batch size for testing\n","    epochs = 4,                                 # maximum number of epochs to train\n","    lr = 0.05,                                 # learning rate\n","    momentum = 0.9,                              # SGD momentum, for SGD only\n","    optimizer = 'adam',                          # optimization method: sgd | adam\n","    log_interval = 5,                            # how many batches to wait before logging training status\n","    patience = 5,                                # how many epochs of no loss improvement should we wait before stop training\n","    checkpoint = '../models',                    # checkpoints directory\n","    seed = 42,\n","    train = True,                                # train before testing\n","    cuda = True,                                 # use gpu\n","    num_workers = 2,                             # how many subprocesses to use for data loading\n","    adapter_hidden_size = 64\n",")"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Video ID</th>\n","      <th>Comment</th>\n","      <th>Likes</th>\n","      <th>Sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>wAZZ-UWGVHI</td>\n","      <td>Lets not forget that Apple Pay in 2014 require...</td>\n","      <td>95.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>wAZZ-UWGVHI</td>\n","      <td>Here in NZ 50 of retailers dont even have con...</td>\n","      <td>19.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>wAZZ-UWGVHI</td>\n","      <td>I will forever acknowledge this channel with t...</td>\n","      <td>161.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>wAZZ-UWGVHI</td>\n","      <td>Whenever I go to a place that doesnt take App...</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>wAZZ-UWGVHI</td>\n","      <td>Apple Pay is so convenient secure and easy to ...</td>\n","      <td>34.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>18403</th>\n","      <td>cyLWtMSry58</td>\n","      <td>I really like the point about engineering tool...</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>18404</th>\n","      <td>cyLWtMSry58</td>\n","      <td>Ive just started exploring this field And thi...</td>\n","      <td>20.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>18405</th>\n","      <td>cyLWtMSry58</td>\n","      <td>Excelente video con una pregunta filos贸fica pr...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>18406</th>\n","      <td>cyLWtMSry58</td>\n","      <td>Hey Daniel just discovered your channel a coup...</td>\n","      <td>35.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>18407</th>\n","      <td>cyLWtMSry58</td>\n","      <td>This is great Focus is key A playful approach ...</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>18408 rows  4 columns</p>\n","</div>"],"text/plain":["          Video ID                                            Comment  Likes  \\\n","0      wAZZ-UWGVHI  Lets not forget that Apple Pay in 2014 require...   95.0   \n","1      wAZZ-UWGVHI  Here in NZ 50 of retailers dont even have con...   19.0   \n","2      wAZZ-UWGVHI  I will forever acknowledge this channel with t...  161.0   \n","3      wAZZ-UWGVHI  Whenever I go to a place that doesnt take App...    8.0   \n","4      wAZZ-UWGVHI  Apple Pay is so convenient secure and easy to ...   34.0   \n","...            ...                                                ...    ...   \n","18403  cyLWtMSry58  I really like the point about engineering tool...    0.0   \n","18404  cyLWtMSry58  Ive just started exploring this field And thi...   20.0   \n","18405  cyLWtMSry58  Excelente video con una pregunta filos贸fica pr...    1.0   \n","18406  cyLWtMSry58  Hey Daniel just discovered your channel a coup...   35.0   \n","18407  cyLWtMSry58  This is great Focus is key A playful approach ...    0.0   \n","\n","       Sentiment  \n","0            1.0  \n","1            0.0  \n","2            2.0  \n","3            0.0  \n","4            2.0  \n","...          ...  \n","18403        2.0  \n","18404        2.0  \n","18405        1.0  \n","18406        2.0  \n","18407        2.0  \n","\n","[18408 rows x 4 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["from data import make_dataset\n","\n","data_raw = \"../data/raw/comments.csv\"\n","df_raw = pd.read_csv(data_raw, index_col=0, sep=',')\n","df_clean = make_dataset.clean_data(df_raw)\n","df_clean"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"ename":"ParserError","evalue":"Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn [7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfeatures\u001b[39;00m \u001b[39mimport\u001b[39;00m build_features\n\u001b[1;32m      3\u001b[0m data_clean \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../data/processed/comments_clean.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m comments, target \u001b[39m=\u001b[39m build_features\u001b[39m.\u001b[39;49mpreprocess(data_clean\u001b[39m=\u001b[39;49mdata_clean, text_col\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mComment\u001b[39;49m\u001b[39m'\u001b[39;49m, target_col\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mSentiment\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(comments, target, test_size\u001b[39m=\u001b[39m\u001b[39m0.33\u001b[39m, random_state\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mseed)\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/site-packages/features/build_features.py:24\u001b[0m, in \u001b[0;36mpreprocess\u001b[0;34m(data_clean, text_col, target_col)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess\u001b[39m(data_clean\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../../data/processed/comments_clean.csv\u001b[39m\u001b[39m'\u001b[39m, text_col\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mComments\u001b[39m\u001b[39m'\u001b[39m, target_col\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSentiment\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     23\u001b[0m     \u001b[39m\"\"\"TODO: finish documentation\"\"\"\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     df_clean \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(data_clean, index_col\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     25\u001b[0m     comments \u001b[39m=\u001b[39m df_clean[text_col]\u001b[39m.\u001b[39mtolist()  \u001b[39m# The tokenizer recieves a list as input\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     target \u001b[39m=\u001b[39m prepare_target(df_clean[target_col])\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/site-packages/pandas/io/parsers/readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    580\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 581\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1255\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1253\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1254\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1255\u001b[0m     index, columns, col_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(nrows)\n\u001b[1;32m   1256\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1257\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:225\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> 225\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[1;32m    226\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    227\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:805\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:847\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1960\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n","\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n"]}],"source":["from features import build_features\n","\n","data_clean = '../data/processed/comments_clean.csv'\n","comments, target = build_features.preprocess(data_clean=data_clean, text_col='Comment', target_col='Sentiment')\n","X_train, X_test, y_train, y_test = train_test_split(comments, target, test_size=0.33, random_state=args.seed)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Video ID</th>\n","      <th>Comment</th>\n","      <th>Likes</th>\n","      <th>Sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>wAZZ-UWGVHI</td>\n","      <td>Let's not forget that Apple Pay in 2014 requir...</td>\n","      <td>95.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>wAZZ-UWGVHI</td>\n","      <td>Here in NZ 50% of retailers dont even have co...</td>\n","      <td>19.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>wAZZ-UWGVHI</td>\n","      <td>I will forever acknowledge this channel with t...</td>\n","      <td>161.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>wAZZ-UWGVHI</td>\n","      <td>Whenever I go to a place that doesnt take App...</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>wAZZ-UWGVHI</td>\n","      <td>Apple Pay is so convenient, secure, and easy t...</td>\n","      <td>34.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>18404</th>\n","      <td>cyLWtMSry58</td>\n","      <td>I really like the point about engineering tool...</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>18405</th>\n","      <td>cyLWtMSry58</td>\n","      <td>Ive just started exploring this field. And th...</td>\n","      <td>20.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>18406</th>\n","      <td>cyLWtMSry58</td>\n","      <td>Excelente video con una pregunta filos贸fica pr...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>18407</th>\n","      <td>cyLWtMSry58</td>\n","      <td>Hey Daniel, just discovered your channel a cou...</td>\n","      <td>35.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>18408</th>\n","      <td>cyLWtMSry58</td>\n","      <td>This is great. Focus is key. A playful approac...</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>18409 rows  4 columns</p>\n","</div>"],"text/plain":["          Video ID                                            Comment  Likes  \\\n","0      wAZZ-UWGVHI  Let's not forget that Apple Pay in 2014 requir...   95.0   \n","1      wAZZ-UWGVHI  Here in NZ 50% of retailers dont even have co...   19.0   \n","2      wAZZ-UWGVHI  I will forever acknowledge this channel with t...  161.0   \n","3      wAZZ-UWGVHI  Whenever I go to a place that doesnt take App...    8.0   \n","4      wAZZ-UWGVHI  Apple Pay is so convenient, secure, and easy t...   34.0   \n","...            ...                                                ...    ...   \n","18404  cyLWtMSry58  I really like the point about engineering tool...    0.0   \n","18405  cyLWtMSry58  Ive just started exploring this field. And th...   20.0   \n","18406  cyLWtMSry58  Excelente video con una pregunta filos贸fica pr...    1.0   \n","18407  cyLWtMSry58  Hey Daniel, just discovered your channel a cou...   35.0   \n","18408  cyLWtMSry58  This is great. Focus is key. A playful approac...    0.0   \n","\n","       Sentiment  \n","0            1.0  \n","1            0.0  \n","2            2.0  \n","3            0.0  \n","4            2.0  \n","...          ...  \n","18404        2.0  \n","18405        2.0  \n","18406        1.0  \n","18407        2.0  \n","18408        2.0  \n","\n","[18409 rows x 4 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["file = \"../data/raw/comments.csv\"\n","df = pd.read_csv(file, index_col=0, sep=',')\n","df"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["df_train_ids = []\n","df_test_ids = []\n","for i in range(len(df.index)):\n","    if i%10 < 10*0.7:\n","        df_train_ids.append(i)\n","    else:\n","        df_test_ids.append(i)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Video ID</th>\n","      <th>Comment</th>\n","      <th>Likes</th>\n","      <th>Sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>wAZZ-UWGVHI</td>\n","      <td>Let's not forget that Apple Pay in 2014 requir...</td>\n","      <td>95.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>wAZZ-UWGVHI</td>\n","      <td>Here in NZ 50% of retailers dont even have co...</td>\n","      <td>19.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>wAZZ-UWGVHI</td>\n","      <td>I will forever acknowledge this channel with t...</td>\n","      <td>161.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>wAZZ-UWGVHI</td>\n","      <td>Whenever I go to a place that doesnt take App...</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>wAZZ-UWGVHI</td>\n","      <td>Apple Pay is so convenient, secure, and easy t...</td>\n","      <td>34.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>12882</th>\n","      <td>cyLWtMSry58</td>\n","      <td>I come from a physics background, and usually ...</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>12883</th>\n","      <td>cyLWtMSry58</td>\n","      <td>Back when I was learning to code I didnt know...</td>\n","      <td>33.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>12884</th>\n","      <td>cyLWtMSry58</td>\n","      <td>I really like the point about engineering tool...</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>12885</th>\n","      <td>cyLWtMSry58</td>\n","      <td>Ive just started exploring this field. And th...</td>\n","      <td>20.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>12886</th>\n","      <td>cyLWtMSry58</td>\n","      <td>Excelente video con una pregunta filos贸fica pr...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>12887 rows  4 columns</p>\n","</div>"],"text/plain":["          Video ID                                            Comment  Likes  \\\n","0      wAZZ-UWGVHI  Let's not forget that Apple Pay in 2014 requir...   95.0   \n","1      wAZZ-UWGVHI  Here in NZ 50% of retailers dont even have co...   19.0   \n","2      wAZZ-UWGVHI  I will forever acknowledge this channel with t...  161.0   \n","3      wAZZ-UWGVHI  Whenever I go to a place that doesnt take App...    8.0   \n","4      wAZZ-UWGVHI  Apple Pay is so convenient, secure, and easy t...   34.0   \n","...            ...                                                ...    ...   \n","12882  cyLWtMSry58  I come from a physics background, and usually ...    5.0   \n","12883  cyLWtMSry58  Back when I was learning to code I didnt know...   33.0   \n","12884  cyLWtMSry58  I really like the point about engineering tool...    0.0   \n","12885  cyLWtMSry58  Ive just started exploring this field. And th...   20.0   \n","12886  cyLWtMSry58  Excelente video con una pregunta filos贸fica pr...    1.0   \n","\n","       Sentiment  \n","0            1.0  \n","1            0.0  \n","2            2.0  \n","3            0.0  \n","4            2.0  \n","...          ...  \n","12882        2.0  \n","12883        1.0  \n","12884        2.0  \n","12885        2.0  \n","12886        1.0  \n","\n","[12887 rows x 4 columns]"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["df_train = df.loc[df_train_ids].copy().reset_index(drop=True)\n","df_train"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["'Liquid nitrogen never ends\\nM4tech poli'"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df['Comment'][33]"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["game is on \n","game is on fire \n"]}],"source":["import emoji\n","import re\n","\n","text = \"game is on \"\n","#text = df['Comment'][33]\n","print(text)\n","text_clean = emoji.demojize(text, delimiters=(\" \", \" \"))\n","text_clean = re.sub(' +', ' ', text_clean)\n","print(text_clean)\n"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Video ID</th>\n","      <th>Comment</th>\n","      <th>Likes</th>\n","      <th>Sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>wAZZ-UWGVHI</td>\n","      <td>Let's not forget that Apple Pay in 2014 requir...</td>\n","      <td>95.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>wAZZ-UWGVHI</td>\n","      <td>Here in NZ 50% of retailers dont even have co...</td>\n","      <td>19.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>wAZZ-UWGVHI</td>\n","      <td>I will forever acknowledge this channel with t...</td>\n","      <td>161.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>wAZZ-UWGVHI</td>\n","      <td>Whenever I go to a place that doesnt take App...</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>wAZZ-UWGVHI</td>\n","      <td>Apple Pay is so convenient, secure, and easy t...</td>\n","      <td>34.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>18403</th>\n","      <td>cyLWtMSry58</td>\n","      <td>I really like the point about engineering tool...</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>18404</th>\n","      <td>cyLWtMSry58</td>\n","      <td>Ive just started exploring this field. And th...</td>\n","      <td>20.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>18405</th>\n","      <td>cyLWtMSry58</td>\n","      <td>Excelente video con una pregunta filos贸fica pr...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>18406</th>\n","      <td>cyLWtMSry58</td>\n","      <td>Hey Daniel, just discovered your channel a cou...</td>\n","      <td>35.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>18407</th>\n","      <td>cyLWtMSry58</td>\n","      <td>This is great. Focus is key. A playful approac...</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>18408 rows  4 columns</p>\n","</div>"],"text/plain":["          Video ID                                            Comment  Likes  \\\n","0      wAZZ-UWGVHI  Let's not forget that Apple Pay in 2014 requir...   95.0   \n","1      wAZZ-UWGVHI  Here in NZ 50% of retailers dont even have co...   19.0   \n","2      wAZZ-UWGVHI  I will forever acknowledge this channel with t...  161.0   \n","3      wAZZ-UWGVHI  Whenever I go to a place that doesnt take App...    8.0   \n","4      wAZZ-UWGVHI  Apple Pay is so convenient, secure, and easy t...   34.0   \n","...            ...                                                ...    ...   \n","18403  cyLWtMSry58  I really like the point about engineering tool...    0.0   \n","18404  cyLWtMSry58  Ive just started exploring this field. And th...   20.0   \n","18405  cyLWtMSry58  Excelente video con una pregunta filos贸fica pr...    1.0   \n","18406  cyLWtMSry58  Hey Daniel, just discovered your channel a cou...   35.0   \n","18407  cyLWtMSry58  This is great. Focus is key. A playful approac...    0.0   \n","\n","       Sentiment  \n","0            1.0  \n","1            0.0  \n","2            2.0  \n","3            0.0  \n","4            2.0  \n","...          ...  \n","18403        2.0  \n","18404        2.0  \n","18405        1.0  \n","18406        2.0  \n","18407        2.0  \n","\n","[18408 rows x 4 columns]"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["df_clean = df.dropna().reset_index(drop=True)\n","\n","for idx, row in df_clean.iterrows():\n","    text = row['Comment']\n","    text_clean = emoji.demojize(text, delimiters=(\" \", \" \"))\n","    text_clean = re.sub(' +', ' ', text_clean)\n","    df_clean.loc[idx,'Comment'] = text_clean\n","\n","df_clean"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Dhlu1WF3bJqW"},"outputs":[],"source":["class Loader(torch.utils.data.Dataset):\n","  def __init__(self, comments, sentiments):\n","    self.data= tokenizer(comments, padding=True, truncation = True, max_length=512,return_tensors=\"pt\")['input_ids']\n","    self.target = sentiments\n","    \n","  def __getitem__(self, index):\n","    data = self.data[index]\n","    target = self.target[index]\n","    return data, target\n","  \n","  def __len__(self):\n","        return len(self.target)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"L1Kxe-9X81O4"},"outputs":[],"source":["class DistilBERTforSentiment(nn.Module):\n","    def __init__(self, adapter_hidden_size=64):\n","        super().__init__()\n","\n","        self.distilbert = DistilBertModel.from_pretrained(MODEL)\n","        \n","        hidden_size = self.distilbert.config.hidden_size\n","\n","        self.adaptor = nn.Sequential(\n","            nn.Linear(hidden_size, adapter_hidden_size),\n","            nn.ReLU(True),           \n","            nn.Dropout(0.1),            \n","            nn.Linear(adapter_hidden_size, hidden_size),\n","        )  \n","        \n","        self.classifier = nn.Sequential(\n","            nn.Linear(hidden_size, adapter_hidden_size),\n","            nn.ReLU(True),           \n","            nn.Dropout(0.1),            \n","            nn.Linear(adapter_hidden_size, 3),\n","        )\n","        \n","        \n","    def forward(self, inputs):\n","        outputs = self.distilbert(input_ids = inputs, return_dict=False)\n","        # B x seq_length x H\n","        x = self.adaptor(outputs[0])\n","        \n","        x,_ = x.max(dim=1)\n","        # B x H\n","        \n","        results = self.classifier(x)\n","        return results"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Z7FSqdQP8uUE","outputId":"89ef64da-dc4d-4f70-99f0-f381d766041f"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["args.cuda = args.cuda and torch.cuda.is_available()\n","if args.cuda:\n","    print('Using CUDA with {0} GPUs'.format(torch.cuda.device_count()))\n","\n","# build model\n","model = DistilBERTforSentiment(adapter_hidden_size=args.adapter_hidden_size)\n","\n","for param in model.distilbert.parameters():\n","    param.requires_grad = False\n","    \n","if args.cuda:\n","    model.cuda()\n","\n","# Define criterion\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"-q2rd9cY78UT"},"outputs":[],"source":["def train_one_epoch(trainloader, model, criterion, optimizer, epoch_index, cuda,max_norm=1):\n","    model.train()\n","    running_loss = 0\n","    accumulation_steps = 40 # effective 40 batch  \n","    for i, (input_ids,target) in enumerate(trainloader, 0):\n","        if cuda:\n","            input_ids, target = input_ids.cuda(), target.cuda()\n","        #optimizer.zero_grad()\n","        output = model(input_ids)\n","        loss = criterion(output, target)\n","        #print(torch.sigmoid(output), target)\n","        loss.backward()\n","        nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n","        if (i+1) % accumulation_steps == 0:\n","            optimizer.step()                 # Now we can do an optimizer step\n","            optimizer.zero_grad()\n","        running_loss += loss.item()\n","        if i % 1000 == 999:\n","            last_loss = running_loss / 1000 # loss per batch\n","            print('  batch {} loss: {}'.format(i + 1, last_loss))\n","            tb_x = epoch_index * len(trainloader) + i + 1\n","            print('Loss/train', last_loss, tb_x)\n","            running_loss = 0.\n","    return running_loss / i"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"3VA1U9FoBDl7"},"outputs":[],"source":["def test_one_epoch(test_loader,model,criterion, cuda, avg_loss):\n","    running_vloss = 0.0\n","    best_vloss = 99999\n","    for i, (input_ids,target) in enumerate(test_loader, 0):\n","        if cuda:\n","            input_ids, target = input_ids.cuda(), target.cuda()\n","        output = model(input_ids)\n","        loss = criterion(output, target)\n","        running_vloss += loss\n","\n","    avg_vloss = running_vloss / (i + 1)\n","    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n","    return avg_vloss"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"VszQ1drb_TqY","outputId":"9516892e-3eb3-4127-dae4-8d012cb0cae8"},"outputs":[],"source":["# num_workers set to 8 as recommended when training in local\n","training_set = Loader(X_train, y_train) #X['attention_mask']\n","train_loader = torch.utils.data.DataLoader(training_set, batch_size=1,\n","                                          shuffle=True, num_workers=8)\n","\n","test_set = Loader(X_test, y_test) #X['attention_mask']\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=1,\n","                                          shuffle=True, num_workers=8)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["<torch.utils.data.dataloader.DataLoader at 0x144b4c280>"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["train_loader"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"MW-ps82g8Tj0","outputId":"bf180970-8caa-4fa0-8a26-d2e1cb7c6742"},"outputs":[{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n","    exitcode = _main(fd, parent_sentinel)\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n","    self = reduction.pickle.load(from_parent)\n","AttributeError: Can't get attribute 'Loader' on <module '__main__' (built-in)>\n","    exitcode = _main(fd, parent_sentinel)\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n","    self = reduction.pickle.load(from_parent)\n","AttributeError: Can't get attribute 'Loader' on <module '__main__' (built-in)>\n","Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n","    exitcode = _main(fd, parent_sentinel)\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n","    self = reduction.pickle.load(from_parent)\n","AttributeError: Can't get attribute 'Loader' on <module '__main__' (built-in)>\n","Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n","    exitcode = _main(fd, parent_sentinel)\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n","    self = reduction.pickle.load(from_parent)\n","AttributeError: Can't get attribute 'Loader' on <module '__main__' (built-in)>\n","Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n","    exitcode = _main(fd, parent_sentinel)\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n","    self = reduction.pickle.load(from_parent)\n","AttributeError: Can't get attribute 'Loader' on <module '__main__' (built-in)>\n","Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n","    exitcode = _main(fd, parent_sentinel)\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n","    self = reduction.pickle.load(from_parent)\n","AttributeError: Can't get attribute 'Loader' on <module '__main__' (built-in)>\n","Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n","    exitcode = _main(fd, parent_sentinel)\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n","    self = reduction.pickle.load(from_parent)\n","AttributeError: Can't get attribute 'Loader' on <module '__main__' (built-in)>\n","Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n","    exitcode = _main(fd, parent_sentinel)\n","  File \"/Users/polvilavella/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n","    self = reduction.pickle.load(from_parent)\n","AttributeError: Can't get attribute 'Loader' on <module '__main__' (built-in)>\n"]},{"ename":"RuntimeError","evalue":"DataLoader worker (pid(s) 36354, 36357) exited unexpectedly","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1164\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    114\u001b[0m     \u001b[39mraise\u001b[39;00m Empty\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 262\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/connection.py:429\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 429\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    430\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     64\u001b[0m     \u001b[39m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     _error_if_any_worker_fails()\n\u001b[1;32m     67\u001b[0m     \u001b[39mif\u001b[39;00m previous_handler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 36357) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn [15], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m best_valid_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m9999\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (epoch \u001b[38;5;241m<\u001b[39m args\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m         train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m         valid_loss \u001b[38;5;241m=\u001b[39m test_one_epoch(test_loader, model, criterion, args\u001b[38;5;241m.\u001b[39mcuda, train_loss)\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(args\u001b[38;5;241m.\u001b[39mcheckpoint):\n","Cell \u001b[0;32mIn [10], line 5\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(trainloader, model, criterion, optimizer, epoch_index, cuda, max_norm)\u001b[0m\n\u001b[1;32m      3\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m accumulation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m40\u001b[39m \u001b[38;5;66;03m# effective 40 batch  \u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (input_ids,target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cuda:\n\u001b[1;32m      7\u001b[0m         input_ids, target \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mcuda(), target\u001b[38;5;241m.\u001b[39mcuda()\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1356\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1358\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1359\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1361\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1362\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1325\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1324\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1325\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1326\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1327\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n","File \u001b[0;32m~/opt/anaconda3/envs/taed/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1176\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(failed_workers) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1175\u001b[0m     pids_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(w\u001b[39m.\u001b[39mpid) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1176\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mDataLoader worker (pid(s) \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) exited unexpectedly\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(pids_str)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, queue\u001b[39m.\u001b[39mEmpty):\n\u001b[1;32m   1178\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n","\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 36354, 36357) exited unexpectedly"]}],"source":["optimizer = optim.Adam(model.parameters(), lr=args.lr)\n","epoch = 0\n","best_valid_loss = 9999\n","while (epoch < args.epochs + 1):\n","        train_loss = train_one_epoch(train_loader, model, criterion, optimizer, epoch, args.cuda)\n","        valid_loss = test_one_epoch(test_loader, model, criterion, args.cuda, train_loss)\n","        if not os.path.isdir(args.checkpoint):\n","            os.mkdir(args.checkpoint)\n","        torch.save(model.state_dict(), '../models/{}/model{:03d}.pt'.format(args.checkpoint, epoch))\n","        if valid_loss <= best_valid_loss:\n","            print('Saving state')\n","            best_valid_loss = valid_loss\n","            best_epoch = epoch\n","            state = {\n","                'valid_loss': valid_loss,\n","                'epoch': epoch,\n","            }\n","            if not os.path.isdir(args.checkpoint):\n","                os.mkdir(args.checkpoint)\n","            torch.save(state, './{}/ckpt.pt'.format(args.checkpoint))\n","        print(\"End epoch \", epoch)\n","        epoch += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yTLw_iE-J_l6"},"outputs":[],"source":["'''class BertforSentiment(nn.Module):\n","  def __init__(self, adapter_hidden_size=64):\n","        super().__init__()\n","        self.distilbert = Distilbert.from_pretrained(MODEL)\n","        self.hidden_size = self.distilhubert.config.hidden_size\n","        self.adaptor = nn.Sequential(\n","            nn.Linear(3*self.hidden_size, adapter_hidden_size),\n","            nn.ReLU(True),           \n","            nn.Dropout(0.1),            \n","            nn.Linear(adapter_hidden_size, self.hidden_size*3),\n","        )  \n","        \n","        self.classifier = nn.Sequential(\n","            nn.Linear(3*self.hidden_size, adapter_hidden_size),\n","            nn.ReLU(True),           \n","            nn.Dropout(0.1),            \n","            nn.Linear(adapter_hidden_size, 1),\n","        )\n","        num_layers = self.distilhubert.config.num_hidden_layers + 1 # transformer layers + input embeddings\n","        self.layer_weights = nn.Parameter(torch.tensor([1/3, 1/3, 1/3], dtype = torch.float32), requires_grad = True)'''\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 ('taed')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"025c0aba4221b3da9a885e5aca70245362a44602d165372a325b50456c8902a4"}}},"nbformat":4,"nbformat_minor":4}
