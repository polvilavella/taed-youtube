{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Notebook for training and testing the model"]},{"cell_type":"markdown","metadata":{},"source":["Installing packages"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"acdbeff9-0075-47ea-95a9-9d40b5d3c3d6","_uuid":"91894eee-954f-4921-9c69-8a181367d177","collapsed":false,"execution":{"iopub.execute_input":"2022-10-19T06:46:52.351736Z","iopub.status.busy":"2022-10-19T06:46:52.351254Z","iopub.status.idle":"2022-10-19T06:47:09.107575Z","shell.execute_reply":"2022-10-19T06:47:09.106181Z","shell.execute_reply.started":"2022-10-19T06:46:52.351659Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["pip install mlflow"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"38a8f60e-6509-4ea2-ad49-601aaac49dc3","_uuid":"d24ac71e-cf49-43a4-aa7b-e21830bb137f","collapsed":false,"execution":{"iopub.execute_input":"2022-10-19T06:47:09.111846Z","iopub.status.busy":"2022-10-19T06:47:09.111545Z","iopub.status.idle":"2022-10-19T06:47:21.482571Z","shell.execute_reply":"2022-10-19T06:47:21.481191Z","shell.execute_reply.started":"2022-10-19T06:47:09.111814Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["pip install codecarbon"]},{"cell_type":"markdown","metadata":{},"source":["### Definition of the model and data"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e107781e-e20e-460e-bcbb-1790be1a4eb7","_uuid":"96519959-6f65-4cc9-949a-1ad1f254c85a","collapsed":false,"execution":{"iopub.execute_input":"2022-10-19T06:47:54.239510Z","iopub.status.busy":"2022-10-19T06:47:54.239155Z","iopub.status.idle":"2022-10-19T06:53:16.836925Z","shell.execute_reply":"2022-10-19T06:53:16.835889Z","shell.execute_reply.started":"2022-10-19T06:47:54.239476Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.utils.data as data\n","import torch.nn as nn\n","import torch.optim as optim\n","from transformers import DistilBertModel, BertConfig, DistilBertTokenizer\n","from types import SimpleNamespace\n","from torch.utils.data import DataLoader\n","import os\n","import csv\n","from transformers import AutoModel, AutoTokenizer\n","from sklearn.model_selection import train_test_split\n","import mlflow\n","import re\n","\n","from codecarbon import EmissionsTracker\n","\n","MODEL = \"distilbert-base-cased\"\n","\n","\n","tokenizer = DistilBertTokenizer.from_pretrained(MODEL, max_length=512, padding=True, truncation = True, return_tensors=\"pt\")\n","\n","args = SimpleNamespace(\n","    batch_size = 1,             # training and valid batch size\n","    test_batch_size = 1,        # batch size for testing\n","    epochs = 15,                # maximum number of epochs to train\n","    lr = 0.001,                 # learning rate\n","    momentum = 0.9,             # SGD momentum, for SGD only\n","    optimizer = 'adam',         # optimization method: sgd | adam\n","    log_interval = 5,           # number of batches before logging training status\n","    patience = 5,               # number of epochs of no loss improvement before stop training\n","    checkpoint = '.',           #\n","    seed = 42,                  # checkpoints directory\n","    train = True,               # train before testing\n","    cuda = True,                # use gpu\n","    num_workers = 2,            # number of subprocesses to use for data loading\n","    adapter_hidden_size = 32,   #\n","    acc_steps = 20              #\n",")\n","\n","\n","# Given the list with the classes for each comment, returns the output with the desired format\n","def prepare_target(sentiments):\n","    target = []\n","    for sent in sentiments:\n","        if sent == 0:\n","            target.append([1.0,0.0])#,0.0]) #target.append([1.0,0.0])\n","        elif sent == 1:\n","            target.append([0.0,1.0,0.0])\n","        else:\n","            target.append([0.0,1.0])#,1.0]) # target.append([0.0,1.0])\n","    return torch.tensor(target)\n","\n","\n","file = \"/kaggle/input/youtube-statistics/comments_clean.csv\"\n","df_clean = pd.read_csv(file, index_col=0, sep=',')\n","\n","comments = df_clean['Comment'].tolist() # The tokenizer recieves a list as input\n","target = prepare_target(df_clean['Sentiment'])\n","X_train, X_test, y_train, y_test = train_test_split(comments, target, test_size=0.2, random_state=args.seed)\n","X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=args.seed)\n","\n","\n","class Loader(torch.utils.data.Dataset):\n","  def __init__(self, comments, sentiments):\n","    self.data= tokenizer(comments, padding=True, truncation = True, max_length=512,return_tensors=\"pt\")['input_ids']\n","    self.target = sentiments\n","\n","  def __getitem__(self, index):\n","    data = self.data[index]\n","    target = self.target[index]\n","    return data, target\n","\n","  def __len__(self):\n","        return len(self.target)\n","\n","\n","class DistilBERTforSentiment(nn.Module):\n","    def __init__(self, adapter_hidden_size=args.adapter_hidden_size):\n","        super().__init__()\n","\n","        self.distilbert = DistilBertModel.from_pretrained(MODEL)\n","\n","        hidden_size = self.distilbert.config.hidden_size\n","\n","        self.adaptor = nn.Sequential(\n","            nn.Linear(hidden_size, adapter_hidden_size),\n","            nn.ReLU(True),\n","            nn.Dropout(0.2),\n","            nn.Linear(adapter_hidden_size, hidden_size),\n","        )\n","\n","        self.classifier = nn.Sequential(\n","            nn.Linear(hidden_size, adapter_hidden_size),\n","            nn.ReLU(True),\n","            nn.Dropout(0.2),\n","            nn.Linear(adapter_hidden_size, 2),\n","        )\n","\n","\n","    def forward(self, inputs):\n","        outputs = self.distilbert(input_ids = inputs, return_dict=False)\n","        # B x seq_length x H\n","        x = self.adaptor(outputs[0])\n","\n","        x,_ = x.max(dim=1)\n","        # B x H\n","\n","        results = self.classifier(x)\n","        return results\n","\n","\n","args.cuda = args.cuda and torch.cuda.is_available()\n","if args.cuda:\n","    print('Using CUDA with {0} GPUs'.format(torch.cuda.device_count()))\n","\n","# build model\n","model = DistilBERTforSentiment(adapter_hidden_size=args.adapter_hidden_size)"]},{"cell_type":"markdown","metadata":{},"source":["### Definition of the training and testing of one epoch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-19T06:53:16.839499Z","iopub.status.busy":"2022-10-19T06:53:16.839049Z","iopub.status.idle":"2022-10-19T06:53:30.319319Z","shell.execute_reply":"2022-10-19T06:53:30.318223Z","shell.execute_reply.started":"2022-10-19T06:53:16.839459Z"},"trusted":true},"outputs":[],"source":["for param in model.distilbert.parameters():\n","    param.requires_grad = False\n","\n","if args.cuda:\n","    model.cuda()\n","\n","# Define criterion\n","criterion = nn.CrossEntropyLoss()\n","\n","\n","def train_one_epoch(trainloader, model, criterion, optimizer, epoch_index, cuda,max_norm=1):\n","    model.train()\n","    running_loss = 0\n","    accumulation_steps = args.acc_steps # effective  batch\n","    for i, (input_ids,target) in enumerate(trainloader, 0):\n","        if cuda:\n","            input_ids, target = input_ids.cuda(), target.cuda()\n","        output = model(input_ids)\n","\n","        loss = criterion(output, target)\n","        #print(\"output \", output,\" target: \", target, \" \", i)\n","        loss.backward()\n","        #nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n","        if (i+1) % accumulation_steps == 0:\n","            optimizer.step()                 # Now we can do an optimizer step\n","            optimizer.zero_grad()\n","        running_loss += loss.item()\n","        if i % 1000 == 999:\n","            last_loss = running_loss / 1000 # loss per batch\n","            print('  batch {} loss: {}'.format(i + 1, last_loss))\n","            tb_x = epoch_index * len(trainloader) + i + 1\n","            print('Loss/train', last_loss, tb_x)\n","            running_loss = 0.\n","    return running_loss / i\n","\n","\n","def test_one_epoch(test_loader,model,criterion, cuda, avg_loss):\n","    running_vloss = 0.0\n","    best_vloss = 99999\n","    acc = 0\n","    _p = 0.0000000001 # prediction: not pos, target: pos\n","    _n = 0.0000000001 # prediction: not neg, target: neg\n","    _t = 0.0000000001 # prediction: not neutral, target: neutral\n","    pp = 0.0000000001 # prediction: pos, target: pos\n","    nn = 0.0000000001 # prediction: neg, target: neg\n","    tt = 0.0000000001 # prediction: neutral, target: neutral\n","    p_ = 0.0000000001 # prediction: pos, target: not pos\n","    n_ = 0.0000000001 # prediction: neg, target: not neg\n","    t_ = 0.0000000001 # prediction: neutral, target: not neutral\n","    for i, (input_ids,target) in enumerate(test_loader, 0):\n","        if cuda:\n","            input_ids, target = input_ids.cuda(), target.cuda()\n","        output = model(input_ids)\n","        loss = criterion(output, target)\n","        running_vloss += loss\n","        obj = torch.Tensor.int(target.argmax())\n","        out = torch.Tensor.int(output.argmax())\n","        if out == obj:\n","            acc += 1\n","            if obj == 0:\n","                nn += 1\n","            else:\n","                pp += 1\n","            #else:\n","            #    pp += 1\n","        else:\n","            if obj == 0:\n","                _n += 1\n","            else:\n","                _p += 1\n","            #else:\n","            #   _p += 1\n","            if out == 0:\n","                n_ += 1\n","            else:\n","                p_ += 1\n","            #else:\n","            #    p_ += 1\n","\n","    prec_pos = pp/(pp + p_)\n","    prec_neg = nn/(nn + n_)\n","    #prec_neu = tt/(tt + t_)\n","    rec_pos = pp/(pp + _p)\n","    rec_neg = nn/(nn + _n)\n","    #rec_neu = tt/(tt + _t)\n","    avg_vloss = running_vloss / (i + 1)\n","    acc = acc/(i+1)\n","    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n","    print('Accuracy= {}'.format(acc))\n","    return acc, avg_vloss, rec_neg, 0, rec_pos, prec_neg, 0, prec_pos\n","\n","print(\"Preparing training set...\")\n","training_set = Loader(X_train, y_train)\n","train_loader = torch.utils.data.DataLoader(training_set, batch_size=args.batch_size,\n","                                        num_workers=0, shuffle = True)\n","print(\"Preparing validation set...\")\n","\n","valid_set = Loader(X_valid, y_valid)\n","valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=args.test_batch_size,\n","                                           num_workers=0, shuffle = True)"]},{"cell_type":"markdown","metadata":{},"source":["### Training of the model"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b17e01f5-a4e9-42bd-bfe9-bf3e2a5731ba","_uuid":"382eeccb-4d5f-41ff-9dff-50954ce43502","collapsed":false,"execution":{"iopub.execute_input":"2022-10-19T06:53:30.335520Z","iopub.status.busy":"2022-10-19T06:53:30.333886Z","iopub.status.idle":"2022-10-19T07:11:28.195508Z","shell.execute_reply":"2022-10-19T07:11:28.194356Z","shell.execute_reply.started":"2022-10-19T06:53:30.335484Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["optimizer = optim.Adam(model.parameters(), lr=args.lr)\n","epoch = 0\n","best_valid_loss = 9999\n","experiment_name = \"2 classes-2\"#\"40.32.09.003.10\"\n","mlflow.set_tracking_uri(\"https://dagshub.com/danielgonzalbez/taed.mlflow\")\n","os.environ['MLFLOW_TRACKING_USERNAME'] = 'danielgonzalbez'\n","os.environ['MLFLOW_TRACKING_PASSWORD'] = 'iqh601lm'\n","print(\"Creating experiment...\")\n","experiment_id = mlflow.create_experiment(experiment_name)\n","print(\"Starting the experiment...\")\n","\n","\n","tracker = EmissionsTracker()\n","tracker.start()\n","with mlflow.start_run(experiment_id = experiment_id):\n","    mlflow.log_param(\"batch_size\", args.acc_steps)\n","    mlflow.log_param(\"adapter_hidden_size\", args.adapter_hidden_size)\n","    mlflow.log_param(\"momentum\", args.momentum)\n","    mlflow.log_param(\"lr\", args.lr)\n","    mlflow.log_param(\"epochs\", args.epochs)\n","    while (epoch < args.epochs + 1):\n","        train_loss = train_one_epoch(train_loader, model, criterion, optimizer, epoch, args.cuda)\n","        acc, valid_loss, rec_neg, rec_neu, rec_pos, prec_neg, prec_neu, prec_pos = test_one_epoch(valid_loader, model, criterion, args.cuda, train_loss)\n","        if not os.path.isdir(args.checkpoint):\n","            os.mkdir(args.checkpoint)\n","        torch.save(model.state_dict(), './{}/model{:03d}.pt'.format(args.checkpoint, epoch))\n","        if valid_loss <= best_valid_loss:\n","            print('Saving state')\n","            best_valid_loss = valid_loss\n","            best_epoch = epoch\n","            mlflow.log_artifact('./{}/model{:03d}.pt'.format(args.checkpoint, epoch))\n","            state = {\n","                'valid_loss': valid_loss,\n","                'epoch': epoch,\n","            }\n","            if not os.path.isdir(args.checkpoint):\n","                os.mkdir(args.checkpoint)\n","            torch.save(state, './{}/ckpt.pt'.format(args.checkpoint))\n","\n","            print ('logging accuracy...')\n","            mlflow.log_metric(\"accuracy\", acc)\n","            print('logging loss...')\n","            mlflow.log_metric(\"loss\", valid_loss)\n","            mlflow.log_metric(\"Negative recall\", rec_neg)\n","            #mlflow.log_metric(\"Neutral recall\", rec_neu)\n","            mlflow.log_metric(\"Positive recall\", rec_pos)\n","            mlflow.log_metric(\"Negative precision\", prec_neg)\n","            #mlflow.log_metric(\"Neutral precision\", prec_neu)\n","            mlflow.log_metric(\"Positive precision\", prec_pos)\n","            mlflow.log_metric(\"Best epoch\", epoch)\n","        print(\"End epoch \", epoch)\n","\n","        epoch += 1\n","    emissions = tracker.stop()\n","    mlflow.log_metric(\"Emissions\", emissions)"]},{"cell_type":"markdown","metadata":{},"source":["### Model definition for testing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-19T07:11:28.199107Z","iopub.status.busy":"2022-10-19T07:11:28.198783Z","iopub.status.idle":"2022-10-19T07:11:28.211753Z","shell.execute_reply":"2022-10-19T07:11:28.210824Z","shell.execute_reply.started":"2022-10-19T07:11:28.199079Z"},"trusted":true},"outputs":[],"source":["class DistilBERTforSentiment(nn.Module):\n","    def __init__(self, adapter_hidden_size=32):\n","        super().__init__()\n","\n","        self.distilbert = DistilBertModel.from_pretrained(MODEL)\n","\n","        hidden_size = self.distilbert.config.hidden_size\n","\n","        self.adaptor = nn.Sequential(\n","            nn.Linear(hidden_size, adapter_hidden_size),\n","            nn.ReLU(True),\n","            nn.Dropout(0.2),\n","            nn.Linear(adapter_hidden_size, hidden_size),\n","        )\n","\n","        self.classifier = nn.Sequential(\n","            nn.Linear(hidden_size, adapter_hidden_size),\n","            nn.ReLU(True),\n","            nn.Dropout(0.2),\n","            nn.Linear(adapter_hidden_size, 2),\n","        )\n","\n","    def forward(self, inputs):\n","        outputs = self.distilbert(input_ids = inputs, return_dict=False)\n","        # B x seq_length x H\n","        x = self.adaptor(outputs[0])\n","\n","        x,_ = x.max(dim=1)\n","        # B x H\n","\n","        results = self.classifier(x)\n","        return results\n","\n","\n","def make_model():\n","    model = DistilBERTforSentiment(adapter_hidden_size=32)\n","    return model\n","\n","\n","class Loader(torch.utils.data.Dataset):\n","    def __init__(self, comments, sentiments):\n","        self.data= tokenizer(comments, padding=True, truncation = True, max_length=512,return_tensors=\"pt\")['input_ids']\n","        self.target = sentiments\n","\n","    def __getitem__(self, index):\n","        data = self.data[index]\n","        target = self.target[index]\n","        return data, target\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","\n","def prepare_pred(comment, sentiment):\n","    pre_loader = Loader(comment, [1])\n","    loader = torch.utils.data.DataLoader(pre_loader, batch_size=1,\n","                                          shuffle=True, num_workers=0)\n","    return loader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-19T07:11:28.213684Z","iopub.status.busy":"2022-10-19T07:11:28.213310Z","iopub.status.idle":"2022-10-19T07:11:31.528034Z","shell.execute_reply":"2022-10-19T07:11:31.526449Z","shell.execute_reply.started":"2022-10-19T07:11:28.213646Z"},"trusted":true},"outputs":[],"source":["state = torch.load('./{}/ckpt.pt'.format(args.checkpoint))\n","epoch = state['epoch']\n","print(\"Testing model (epoch {})\".format(epoch))\n","#model.load_state_dict(torch.load('./{}/model{:03d}.pt'.format(args.checkpoint, epoch)))\n","\n","model = make_model()\n","model.load_state_dict(torch.load('./{}/model{:03d}.pt'.format(args.checkpoint, epoch)))\n","model.eval()"]},{"cell_type":"markdown","metadata":{},"source":["### Test the model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-19T07:11:31.536588Z","iopub.status.busy":"2022-10-19T07:11:31.533400Z","iopub.status.idle":"2022-10-19T07:11:33.088839Z","shell.execute_reply":"2022-10-19T07:11:33.087775Z","shell.execute_reply.started":"2022-10-19T07:11:31.536557Z"},"trusted":true},"outputs":[],"source":["test_set = Loader(X_test, y_test)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=args.test_batch_size,\n","                                           num_workers=0, shuffle = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-19T07:11:33.090982Z","iopub.status.busy":"2022-10-19T07:11:33.090272Z","iopub.status.idle":"2022-10-19T07:23:30.032661Z","shell.execute_reply":"2022-10-19T07:23:30.031431Z","shell.execute_reply.started":"2022-10-19T07:11:33.090945Z"},"trusted":true},"outputs":[],"source":["acc = 0\n","num1 = 0\n","num0 = 0\n","\n","# i_j = Predicted i, Target j\n","_p = 0.0000000001 # prediction: not pos, target: pos\n","_n = 0.0000000001 # prediction: not neg, target: neg\n","_t = 0.0000000001 # prediction: not neutral, target: neutral\n","pp = 0.0000000001 # prediction: pos, target: pos\n","nn = 0.0000000001 # prediction: neg, target: neg\n","tt = 0.0000000001 # prediction: neutral, target: neutral\n","p_ = 0.0000000001 # prediction: pos, target: not pos\n","n_ = 0.0000000001 # prediction: neg, target: not neg\n","t_ = 0.0000000001 # prediction: neutral, target: not neutral\n","\n","for i, (input_ids, target) in enumerate(test_loader):\n","    output = model(input_ids)\n","    obj = torch.Tensor.int(target.argmax())\n","    out = torch.Tensor.int(output.argmax())\n","    if out == obj:\n","        acc += 1\n","        if obj == 0:\n","            nn += 1\n","        else:\n","            pp += 1\n","        #else:\n","        #    pp += 1\n","    else:\n","        if obj == 0:\n","            _n += 1\n","        else:\n","            _p += 1\n","        #else:\n","        #   _p += 1\n","        if out == 0:\n","            n_ += 1\n","        else:\n","            p_ += 1\n","        #else:\n","        #    p_ += 1\n","    if(i%100 == 0):\n","        print(i, \" \",acc/(i+1))\n","\n","prec_pos = pp/(pp + p_)\n","prec_neg = nn/(nn + n_)\n","#prec_neu = tt/(tt + t_)\n","rec_pos = pp/(pp + _p)\n","rec_neg = nn/(nn + _n)\n","#rec_neu = tt/(tt + _t)\n","print(\"FINAL ACCURACY: \", acc/i)\n","print(\"Positive Recall: \", rec_pos)\n","print(\"Negative Recall: \", rec_neg)\n","#print(\"Neutral Recall: \", rec_neu)\n","print(\"Negative Precision: \", prec_neg)\n","#print(\"Neutral Precision: \", prec_neu)\n","print(\"Positive Precision: \", prec_pos)\n","\n","\n","print(\"F1-Score Positive: \", (2*prec_pos*rec_pos/(prec_pos+rec_pos)))\n","print(\"F1-Score Negative: \", (2*prec_neg*rec_neg/(prec_neg+rec_neg)))\n"]},{"cell_type":"markdown","metadata":{},"source":["Predictions of some invented comments"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-18T16:00:51.636686Z","iopub.status.busy":"2022-10-18T16:00:51.636252Z","iopub.status.idle":"2022-10-18T16:00:51.682544Z","shell.execute_reply":"2022-10-18T16:00:51.681451Z","shell.execute_reply.started":"2022-10-18T16:00:51.636649Z"},"trusted":true},"outputs":[],"source":["load = (prepare_pred(\"Bad video. Waste of time\", [1]))\n","for i, (input_ids,_) in enumerate(load):\n","    out2 = model(input_ids)\n","print(out2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["load = (prepare_pred(\"Good video. Well done\", [1]))\n","for i, (input_ids,_) in enumerate(load):\n","    out2 = model(input_ids)\n","print(out2)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 ('venv': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"685e4261166fabcf7bde24f9d1ca34ef72819d2c1a7785409b518a2a652c42f5"}}},"nbformat":4,"nbformat_minor":4}
